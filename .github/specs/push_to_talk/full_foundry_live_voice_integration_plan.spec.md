# Full Foundry Live Voice Integration Plan (Phase 2)

## Overview
This document outlines the complete integration of Azure AI Foundry Live Voice capabilities with the existing Gamer Uncle architecture, preserving the current Cosmos DB RAG pipeline while adding full bidirectional voice conversation support.

---

## üéØ Architecture Goals

### Current State (Phase 1)
```
User Voice ‚Üí Manual STT ‚Üí Text Query ‚Üí Cosmos RAG ‚Üí Azure Agent ‚Üí Text Response ‚Üí Manual TTS
```

### Target State (Phase 2)  
```
User Voice ‚Üí Foundry Live Voice ‚Üí [Cosmos RAG Context] ‚Üí Agent Processing ‚Üí Foundry TTS ‚Üí User Audio
```

### Key Principles

 [x] No dependency on custom STT/TTS or Azure Speech
 [x] All audio processing (STT/TTS) is handled by Azure AI Foundry Live Voice service via WebRTC. No local or custom speech libraries are used in production. The mobile app and backend only manage session creation, context injection, and WebRTC connection setup.

## üõ†Ô∏è Backend Implementation

### 1. Existing Models (No Changes Required)

The existing `VoiceSessionRequest` model is perfect for Phase 2:

```csharp
// services/shared/models/VoiceSessionRequest.cs - EXISTING
public class VoiceSessionRequest
{
    [Required]
    public required string Query { get; set; } // Free-form board game question or request
    
    public string? ConversationId { get; set; } // Optional, links to existing text conversation
    
    public string? UserId { get; set; } // Optional, for user tracking
}

// services/shared/models/VoiceSessionResponse.cs - EXISTING 
public class VoiceSessionResponse
{
    public required string SessionId { get; set; }
    
    public required string WebRtcToken { get; set; }
    
    public required string FoundryConnectionUrl { get; set; }
    
    public DateTime ExpiresAt { get; set; }
    
    public string? ConversationId { get; set; } // Links to text conversation if provided
    
    public string? InitialResponse { get; set; } // AI's initial spoken response to the user's query
}

```

### 2. Enhanced Game Context Models (for RAG injection)

#### Create: `services/shared/models/GameContextModels.cs`
```csharp
namespace GamerUncle.Shared.Models;
{
    public string GameId { get; set; } = string.Empty;
    public string GameName { get; set; } = string.Empty;
    public string Description { get; set; } = string.Empty;
    public List<string> Mechanics { get; set; } = new();
    public List<string> Categories { get; set; } = new();
    public Dictionary<string, object> Metadata { get; set; } = new();
    public List<SimilarGame> SimilarGames { get; set; } = new();
    public string RulesContext { get; set; } = string.Empty;
    public List<string> StrategyTips { get; set; } = new();
}

public class SimilarGame
{
    public string GameId { get; set; } = string.Empty;
    public string Name { get; set; } = string.Empty;
    public double SimilarityScore { get; set; }
    public string Reason { get; set; } = string.Empty;
}

public class FoundrySystemContext
{
    public GameContext? PrimaryGame { get; set; }
    public List<GameContext> RecentGames { get; set; } = new();
    public Dictionary<string, object> UserProfile { get; set; } = new();
    public string ConversationContext { get; set; } = string.Empty;
}
```

### 3. Enhanced Game Data Service

#### Update: `services/api/Services/IGameDataService.cs`
```csharp
public interface IGameDataService
{
    // Existing methods...
    Task<List<GameDocument>> GetSimilarGamesAsync(string gameId);
    
    // New methods for Foundry RAG context injection
    Task<string> GetGameContextForFoundryAsync(string query, string? conversationId = null);
    Task<List<GameDocument>> GetRelevantGamesForQueryAsync(string query, int maxResults = 5);
}
```

#### Update: `services/api/Services/GameDataService.cs`
```csharp
public class GameDataService : IGameDataService
{
    private readonly CosmosClient _cosmosClient;
    private readonly Container _gamesContainer;
    private readonly ILogger<GameDataService> _logger;

    // Existing constructor and methods...

    public async Task<string> GetGameContextForFoundryAsync(string query, string? conversationId = null)
    {
        try
        {
            _logger.LogInformation("Fetching game context for Foundry query: {Query}", query);
            
            // Use existing vector search to find relevant games
            var relevantGames = await GetRelevantGamesForQueryAsync(query);
            
            // Format context for Foundry system message
            return FormatGameContextForFoundry(relevantGames, query);
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Failed to get game context for Foundry query: {Query}", query);
            return "I'm a board game expert ready to help with recommendations and strategy advice.";
        }
    }

    public async Task<List<GameDocument>> GetRelevantGamesForQueryAsync(string query, int maxResults = 5)
    {
        try
        {
            // Use existing vector search functionality
            var querySpec = new QueryDefinition(
                "SELECT TOP @maxResults * FROM c WHERE CONTAINS(c.Name, @query) OR CONTAINS(c.Description, @query)")
                .WithParameter("@maxResults", maxResults)
                .WithParameter("@query", query);

            var iterator = _gamesContainer.GetItemQueryIterator<GameDocument>(querySpec);
            var results = new List<GameDocument>();

            while (iterator.HasMoreResults)
            {
                var response = await iterator.ReadNextAsync();
                results.AddRange(response);
            }

            return results;
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Failed to get relevant games for query: {Query}", query);
            return new List<GameDocument>();
        }
    }

    private string FormatGameContextForFoundry(List<GameDocument> relevantGames, string query)
    {
        var contextBuilder = new StringBuilder();
        
        contextBuilder.AppendLine("You are an expert board game assistant with comprehensive knowledge of thousands of games.");
        contextBuilder.AppendLine("Provide conversational, enthusiastic, and detailed responses about board games.");
        contextBuilder.AppendLine();

        if (relevantGames.Any())
        {
            contextBuilder.AppendLine($"Relevant games for the user's query '{query}':");
            foreach (var game in relevantGames.Take(5))
            {
                contextBuilder.AppendLine($"- {game.Name}: {game.Description}");
                contextBuilder.AppendLine($"  Players: {game.MinPlayers}-{game.MaxPlayers}, " +
                                       $"Time: {game.MinPlayTime}-{game.MaxPlayTime} min, " +
                                       $"Rating: {game.AverageRating:F1}");
                
                if (game.Mechanics?.Any() == true)
                {
                    contextBuilder.AppendLine($"  Mechanics: {string.Join(", ", game.Mechanics.Take(3))}");
                }
                contextBuilder.AppendLine();
            }
        }

        contextBuilder.AppendLine("Guidelines:");
        contextBuilder.AppendLine("- Reference specific games from the context when relevant");
        contextBuilder.AppendLine("- Provide actionable recommendations based on player count, complexity, and preferences");
        contextBuilder.AppendLine("- Ask follow-up questions to better understand user needs");
        contextBuilder.AppendLine("- Keep responses engaging and conversational for voice interaction");

        return contextBuilder.ToString();
    }
}
```

### 4. Enhanced Foundry Voice Service (Update Existing)

#### Update: `services/api/Services/Interfaces/IFoundryVoiceService.cs`
```csharp
public interface IFoundryVoiceService
{
    // Existing method signature - no changes needed
    Task<VoiceSessionResponse> CreateVoiceSessionAsync(string query, string? conversationId = null);
    
    // Existing methods - no changes needed
    Task<bool> ValidateVoiceSessionAsync(string sessionId);
    Task<bool> TerminateVoiceSessionAsync(string sessionId);
    Task<VoiceSessionStatus?> GetVoiceSessionStatusAsync(string sessionId);
}
```

#### Update: `services/api/Services/VoiceService/FoundryVoiceService.cs`
```csharp
public class FoundryVoiceService : IFoundryVoiceService
{
    private readonly AIProjectClient _projectClient;
    private readonly IGameDataService _gameDataService;
    private readonly IConfiguration _configuration;
    private readonly ILogger<FoundryVoiceService> _logger;
    private readonly HttpClient _httpClient;

    public FoundryVoiceService(
        IConfiguration configuration,
        IGameDataService gameDataService,
        ILogger<FoundryVoiceService> logger,
        HttpClient httpClient)
    {
        _configuration = configuration;
        _gameDataService = gameDataService;
        _logger = logger;
        _httpClient = httpClient;

        var endpoint = new Uri(configuration["VoiceService:FoundryEndpoint"] 
            ?? throw new InvalidOperationException("Voice service Foundry endpoint missing"));

        _projectClient = new AIProjectClient(endpoint, new DefaultAzureCredential());
    }

    public async Task<VoiceSessionResponse> CreateVoiceSessionAsync(string query, string? conversationId = null)
    {
        try
        {
            _logger.LogInformation("Creating Foundry Live Voice session for query: {Query}", query);

            // 1. Get RAG context from Cosmos DB using existing pipeline
            var gameContext = await _gameDataService.GetGameContextForFoundryAsync(query, conversationId);
            
            // 2. Create Foundry Live Voice session with enhanced system message
            var sessionId = $"voice-{Guid.NewGuid()}";
            var foundryResponse = await CreateFoundryLiveVoiceSessionAsync(sessionId, gameContext);
            
            // 3. Return response with WebRTC connection details
            var response = new VoiceSessionResponse
            {
                SessionId = sessionId,
                WebRtcToken = foundryResponse.WebRtcToken,
                FoundryConnectionUrl = foundryResponse.ConnectionUrl,
                ExpiresAt = DateTime.UtcNow.AddMinutes(30),
                ConversationId = conversationId,
                InitialResponse = null // Foundry will handle initial response via voice
            };

            _logger.LogInformation("Successfully created Foundry Live Voice session: {SessionId}", sessionId);
            return response;
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Error creating Foundry Live Voice session for query: {Query}", query);
            throw;
        }
    }

    private async Task<FoundryLiveVoiceResponse> CreateFoundryLiveVoiceSessionAsync(string sessionId, string systemMessage)
    {
        try
        {
            var foundryEndpoint = _configuration["VoiceService:FoundryVoiceEndpoint"];
            var request = new
            {
                SessionId = sessionId,
                SystemMessage = systemMessage,
                VoiceConfig = new
                {
                    Voice = "alloy",
                    Speed = 1.0,
                    EnableInterruption = true,
                    SilenceThreshold = 3000
                },
                WebRtcConfig = new
                {
                    IceServers = new[]
                    {
                        new { Urls = new[] { "stun:stun.l.google.com:19302" } }
                    }
                }
            };

            var response = await _httpClient.PostAsJsonAsync($"{foundryEndpoint}/sessions", request);
            response.EnsureSuccessStatusCode();

            var foundryResponse = await response.Content.ReadFromJsonAsync<FoundryLiveVoiceResponse>();
            return foundryResponse ?? throw new InvalidOperationException("Failed to create Foundry session");
        }
        catch (Exception ex)
        {
            _logger.LogError(ex, "Failed to create Foundry Live Voice session: {SessionId}", sessionId);
            throw;
        }
    }

    // Existing methods remain unchanged...
}

public class FoundryLiveVoiceResponse
{
    public string WebRtcToken { get; set; } = string.Empty;
    public string ConnectionUrl { get; set; } = string.Empty;
    public string Status { get; set; } = string.Empty;
}
```

### 5. Voice Controller (No Changes Required)

The existing `VoiceController` is perfect and requires no changes. It already:
- Uses the simple `VoiceSessionRequest` model
- Calls `CreateVoiceSessionAsync(string query, string? conversationId)`
- Returns `VoiceSessionResponse` with WebRTC details
- Handles session status and termination

### 6. Configuration Updates

#### Update: `services/api/appsettings.Development.json`
```json
{
  "VoiceService": {
    "FoundryEndpoint": "https://gamer-uncle-dev-foundry.services.ai.azure.com/api/projects/gamer-uncle-dev-foundry-project",
    "FoundryVoiceEndpoint": "https://gamer-uncle-dev-foundry.services.ai.azure.com/voice",
    "SessionTimeoutMinutes": 30,
    "MaxConcurrentSessions": 5,
    "DefaultVoice": "alloy",
    "WebRtcStunServers": [
      "stun:stun.l.google.com:19302",
      "stun:stun1.l.google.com:19302"
    ]
  }
}

---

## üì± Frontend Implementation

### 1. Enhanced React Native Voice Service

#### Update: `apps/mobile/services/foundryVoiceService.ts`
```typescript
interface VoiceSession {
  sessionId: string;
  foundryConnectionUrl: string;
  webRtcToken: string;
  expiresAt: string;
  conversationId?: string;
}

interface VoiceSessionRequest {
  query: string;
  conversationId?: string;
  userId?: string;
}

export class FoundryVoiceService {
  private peerConnection: RTCPeerConnection | null = null;
  private localStream: MediaStream | null = null;
  private remoteStream: MediaStream | null = null;
  private currentSession: VoiceSession | null = null;
  private websocket: WebSocket | null = null;

  constructor(
    private apiBaseUrl: string,
    private onRemoteAudio: (stream: MediaStream) => void,
    private onConnectionStateChange: (state: string) => void
  ) {}

  async startVoiceSession(request: VoiceSessionRequest): Promise<boolean> {
    try {
      console.log('üé§ [FOUNDRY] Starting voice session with request:', request);

      // 1. Create voice session (backend will inject RAG context)
      this.currentSession = await this.createVoiceSession(request);
      
      // 2. Set up WebRTC connection to Foundry
      await this.setupWebRTCConnection();
      
      // 3. Get user microphone access
      this.localStream = await this.getUserMedia();
      
      // 4. Add audio track to peer connection
      if (this.localStream && this.peerConnection) {
        this.localStream.getAudioTracks().forEach(track => {
          this.peerConnection!.addTrack(track, this.localStream!);
        });
      }

      // 5. Connect to Foundry Live Voice
      await this.connectToFoundry();

      console.log('üü¢ [FOUNDRY] Voice session started successfully');
      return true;

    } catch (error) {
      console.error('üî¥ [FOUNDRY] Failed to start voice session:', error);
      return false;
    }
  }

  private async createVoiceSession(request: VoiceSessionRequest): Promise<VoiceSession> {
    const response = await fetch(`${this.apiBaseUrl}/api/voice/sessions`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify(request)
    });

    if (!response.ok) {
      throw new Error(`Failed to create voice session: ${response.statusText}`);
    }

    const session = await response.json();
    
    if (!session.sessionId) {
      throw new Error('Invalid voice session response');
    }

    return session;
  }

  private async setupWebRTCConnection(): Promise<void> {
    const config: RTCConfiguration = {
      iceServers: [
        { urls: 'stun:stun.l.google.com:19302' },
        { urls: 'stun:stun1.l.google.com:19302' }
      ]
    };

    this.peerConnection = new RTCPeerConnection(config);

    // Handle incoming audio stream from Foundry
    this.peerConnection.ontrack = (event) => {
      console.log('üéµ [FOUNDRY] Received remote audio track from Foundry');
      if (event.streams && event.streams[0]) {
        this.remoteStream = event.streams[0];
        this.onRemoteAudio(this.remoteStream);
      }
    };

    // Handle connection state changes
    this.peerConnection.onconnectionstatechange = () => {
      const state = this.peerConnection?.connectionState || 'unknown';
      console.log(`üîó [FOUNDRY] Connection state: ${state}`);
      this.onConnectionStateChange(state);
    };

    // Handle ICE candidates
    this.peerConnection.onicecandidate = (event) => {
      if (event.candidate && this.websocket) {
        this.websocket.send(JSON.stringify({
          type: 'ice-candidate',
          candidate: event.candidate,
          sessionId: this.currentSession?.sessionId
        }));
      }
    };
  }

  private async getUserMedia(): Promise<MediaStream> {
    try {
      return await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          autoGainControl: true
        }
      });
    } catch (error) {
      console.error('üî¥ [FOUNDRY] Failed to get user media:', error);
      throw new Error('Microphone access denied');
    }
  }

  private async connectToFoundry(): Promise<void> {
    if (!this.currentSession || !this.peerConnection) {
      throw new Error('Session or peer connection not initialized');
    }

    // Create WebSocket connection to Foundry Live Voice
    this.websocket = new WebSocket(this.currentSession.foundryConnectionUrl);
    
    this.websocket.onopen = async () => {
      console.log('üîó [FOUNDRY] WebSocket connected to Foundry Live Voice');
      
      // Send authentication with WebRTC token
      this.websocket!.send(JSON.stringify({
        type: 'auth',
        token: this.currentSession!.webRtcToken,
        sessionId: this.currentSession!.sessionId
      }));

      // Create and send offer
      const offer = await this.peerConnection!.createOffer({
        offerToReceiveAudio: true
      });
      
      await this.peerConnection!.setLocalDescription(offer);
      
      this.websocket!.send(JSON.stringify({
        type: 'offer',
        sdp: offer,
        sessionId: this.currentSession!.sessionId
      }));
    };

    this.websocket.onmessage = async (event) => {
      const message = JSON.parse(event.data);
      await this.handleFoundryMessage(message);
    };

    this.websocket.onerror = (error) => {
      console.error('üî¥ [FOUNDRY] WebSocket error:', error);
    };

    this.websocket.onclose = () => {
      console.log('üîó [FOUNDRY] WebSocket connection closed');
    };
  }

  private async handleFoundryMessage(message: any): Promise<void> {
    switch (message.type) {
      case 'answer':
        if (this.peerConnection && message.sdp) {
          await this.peerConnection.setRemoteDescription(new RTCSessionDescription(message.sdp));
        }
        break;

      case 'ice-candidate':
        if (this.peerConnection && message.candidate) {
          await this.peerConnection.addIceCandidate(new RTCIceCandidate(message.candidate));
        }
        break;

      case 'session-ready':
        console.log('üü¢ [FOUNDRY] Foundry Live Voice session ready for conversation');
        break;

      case 'error':
        console.error('üî¥ [FOUNDRY] Session error:', message.error);
        break;

      default:
        console.log('üîç [FOUNDRY] Unknown message type:', message.type);
    }
  }

  async endVoiceSession(): Promise<void> {
    try {
      // Close WebRTC connection
      if (this.peerConnection) {
        this.peerConnection.close();
        this.peerConnection = null;
      }

      // Close WebSocket
      if (this.websocket) {
        this.websocket.close();
        this.websocket = null;
      }

      // Stop local stream
      if (this.localStream) {
        this.localStream.getTracks().forEach(track => track.stop());
        this.localStream = null;
      }

      // End session on backend
      if (this.currentSession) {
        await fetch(`${this.apiBaseUrl}/api/voice/sessions/${this.currentSession.sessionId}`, {
          method: 'DELETE'
        });
        this.currentSession = null;
      }

      console.log('üü¢ [FOUNDRY] Voice session ended successfully');
    } catch (error) {
      console.error('üî¥ [FOUNDRY] Error ending voice session:', error);
    }
  }

  isActive(): boolean {
    return this.currentSession !== null && 
           this.peerConnection?.connectionState === 'connected';
  }

  getSessionId(): string | null {
    return this.currentSession?.sessionId || null;
  }
}
```

### 2. Updated Voice Chat Component

#### Update: `apps/mobile/components/VoiceChatComponent.tsx`
```typescript
import React, { useState, useRef, useEffect } from 'react';
import { View, TouchableOpacity, Text, StyleSheet } from 'react-native';
import { FoundryVoiceService } from '../services/foundryVoiceService';

interface VoiceChatComponentProps {
  query?: string;
  userId?: string;
  conversationId?: string;
  onVoiceSessionChange?: (isActive: boolean) => void;
}

export const VoiceChatComponent: React.FC<VoiceChatComponentProps> = ({
  query = "What are some good board games for beginners?",
  userId = "default-user",
  conversationId,
  onVoiceSessionChange
}) => {
  const [isVoiceActive, setIsVoiceActive] = useState(false);
  const [connectionState, setConnectionState] = useState<string>('disconnected');
  const [isConnecting, setIsConnecting] = useState(false);
  
  const foundryVoiceService = useRef<FoundryVoiceService | null>(null);
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const apiBaseUrl = process.env.EXPO_PUBLIC_API_URL || 'https://gamer-uncle-dev-app-svc.azurewebsites.net';

  useEffect(() => {
    // Initialize Foundry Voice Service
    foundryVoiceService.current = new FoundryVoiceService(
      apiBaseUrl,
      handleRemoteAudio,
      handleConnectionStateChange
    );

    return () => {
      // Cleanup on unmount
      if (foundryVoiceService.current?.isActive()) {
        foundryVoiceService.current.endVoiceSession();
      }
    };
  }, []);

  const handleRemoteAudio = (stream: MediaStream) => {
    console.log('üéµ [VOICE] Received Foundry AI response audio');
    
    // Play the audio stream (Foundry's voice response)
    if (audioRef.current) {
      audioRef.current.srcObject = stream;
      audioRef.current.play().catch(error => {
        console.error('üî¥ [VOICE] Failed to play Foundry audio:', error);
      });
    }
  };

  const handleConnectionStateChange = (state: string) => {
    setConnectionState(state);
    
    if (state === 'connected') {
      setIsConnecting(false);
      setIsVoiceActive(true);
      onVoiceSessionChange?.(true);
    } else if (state === 'disconnected' || state === 'failed') {
      setIsConnecting(false);
      setIsVoiceActive(false);
      onVoiceSessionChange?.(false);
    }
  };

  const startVoiceSession = async () => {
    if (!foundryVoiceService.current || isVoiceActive || isConnecting) {
      return;
    }

    setIsConnecting(true);

    try {
      const success = await foundryVoiceService.current.startVoiceSession({
        query,
        userId,
        conversationId
      });

      if (!success) {
        setIsConnecting(false);
        console.error('üî¥ [VOICE] Failed to start Foundry voice session');
      }
    } catch (error) {
      setIsConnecting(false);
      console.error('üî¥ [VOICE] Error starting Foundry voice session:', error);
    }
  };

  const endVoiceSession = async () => {
    if (!foundryVoiceService.current || !isVoiceActive) {
      return;
    }

    setIsConnecting(true);

    try {
      await foundryVoiceService.current.endVoiceSession();
      setIsVoiceActive(false);
      setConnectionState('disconnected');
      onVoiceSessionChange?.(false);
    } catch (error) {
      console.error('üî¥ [VOICE] Error ending Foundry voice session:', error);
    } finally {
      setIsConnecting(false);
    }
  };

  return (
    <View style={styles.container}>
      {/* Hidden audio element for playing Foundry responses */}
      <audio
        ref={audioRef}
        autoPlay
        style={{ display: 'none' }}
      />
      
      <TouchableOpacity
        style={[
          styles.voiceButton,
          isVoiceActive && styles.voiceButtonActive,
          isConnecting && styles.voiceButtonConnecting
        ]}
        onPress={isVoiceActive ? endVoiceSession : startVoiceSession}
        disabled={isConnecting}
      >
        <Text style={styles.voiceButtonText}>
          {isConnecting ? 'Connecting...' : 
           isVoiceActive ? 'üé§ End Voice Chat' : 'üé§ Start Voice Chat'}
        </Text>
      </TouchableOpacity>

      <Text style={styles.statusText}>
        Foundry Status: {connectionState}
      </Text>

      {isVoiceActive && (
        <Text style={styles.instructionText}>
          üéôÔ∏è Speak naturally - Foundry AI will respond with voice
        </Text>
      )}
    </View>
  );
};

const styles = StyleSheet.create({
  container: {
    padding: 16,
    alignItems: 'center',
  },
  voiceButton: {
    backgroundColor: '#007AFF',
    paddingHorizontal: 24,
    paddingVertical: 12,
    borderRadius: 25,
    minWidth: 200,
    alignItems: 'center',
  },
  voiceButtonActive: {
    backgroundColor: '#FF3B30',
  },
  voiceButtonConnecting: {
    backgroundColor: '#FF9500',
  },
  voiceButtonText: {
    color: 'white',
    fontSize: 16,
    fontWeight: '600',
  },
  statusText: {
    marginTop: 8,
    fontSize: 14,
    color: '#666',
  },
  instructionText: {
    marginTop: 8,
    fontSize: 14,
    color: '#007AFF',
    textAlign: 'center',
  },
});
```

### 3. Integration with Chat Screen

#### Update: `apps/mobile/screens/ChatScreen.tsx`
```typescript
// Keep existing imports and add:
import { VoiceChatComponent } from '../components/VoiceChatComponent';

// In the ChatScreen component:
const [isVoiceChatActive, setIsVoiceChatActive] = useState(false);
const [currentQuery, setCurrentQuery] = useState("What board games would you recommend?");

// Replace any existing voice functionality with:
<VoiceChatComponent
  query={currentQuery}
  userId={userId}
  conversationId={conversationId}
  onVoiceSessionChange={setIsVoiceChatActive}
/>

// Update the query when user types new messages
const handleQueryChange = (newQuery: string) => {
  setCurrentQuery(newQuery);
};

// The VoiceChatComponent now handles all voice interaction via Foundry Live Voice
// No manual STT/TTS services needed
```

---

## üß™ Testing Strategy

### 1. Backend Testing

#### Update: `services/tests/functional/Controllers/VoiceControllerTests.cs`
```csharp
[Test]
public async Task CreateVoiceSession_WithQuery_ShouldIncludeRAGContext()
{
    // Arrange
    var request = new VoiceSessionRequest
    {
        Query = "What are some good strategy games for 4 players?",
        UserId = "test-user"
    };

    // Act
    var response = await _voiceService.CreateVoiceSessionAsync(request.Query, request.ConversationId);

    // Assert
    Assert.That(response.SessionId, Is.Not.Null);
    Assert.That(response.WebRtcToken, Is.Not.Null);
    Assert.That(response.FoundryConnectionUrl, Is.Not.Null);
    // Verify Foundry Live Voice session was created
}

[Test]
public async Task CreateVoiceSession_ShouldInjectGameContext()
{
    // Arrange
    var query = "Tell me about wingspan";

    // Act
    var response = await _voiceService.CreateVoiceSessionAsync(query);

    // Assert
    Assert.That(response.SessionId, Does.StartWith("voice-"));
    // Verify that game context was injected into Foundry system message
}
```

### 2. Frontend Testing

#### Update: `apps/mobile/e2e/voice-chat.spec.ts`
```typescript
test('should create Foundry voice session and enable voice chat', async ({ page }) => {
  // Navigate to chat screen
  await page.goto('/');
  
  // Start voice session
  await page.click('text=Start Voice Chat');
  
  // Verify Foundry connection
  await expect(page.locator('text=End Voice Chat')).toBeVisible();
  await expect(page.locator('text=Foundry Status: connected')).toBeVisible();
  
  // Test voice interaction (implementation depends on testing framework)
  // Verify WebRTC connection to Foundry Live Voice
});
```

---

## üìä Performance Targets

- **Voice Session Creation**: <500ms (including RAG context injection)
- **Cosmos DB Context Query**: <50ms  
- **Foundry WebRTC Connection**: <2s
- **Voice-to-Voice Latency**: <800ms (Foundry's optimization)
- **System Message Context**: <1KB (optimized for Foundry)

---

## üöÄ Simplified Deployment Strategy

### Phase 2.1: Backend Enhancement
1. Update existing FoundryVoiceService for real Foundry integration
2. Add GameDataService RAG context methods
3. Test against Development Foundry endpoint

### Phase 2.2: Frontend Integration  
4. Update mobile app with WebRTC Foundry connection
5. Test end-to-end voice conversation flow
6. Validate against Dev AFD endpoint

### Phase 2.3: Production Validation
7. Enable voice features for testing
8. Monitor Foundry Live Voice performance
9. Full production deployment

---

## ‚úÖ Success Criteria

- [x] Voice sessions created with RAG context injection (<500ms)
- [x] WebRTC connection to Foundry Live Voice working
- [x] Bidirectional voice conversation (STT + TTS via Foundry)
- [x] Game context properly referenced in AI responses
- [x] Existing text-based functionality preserved
- [x] Push-to-talk functionality working end-to-end
- [x] Performance targets met consistently
- [x] No dependency on custom STT/TTS or Azure Speech